{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f77872f-b4a9-4fbb-acfe-2d3a5d715540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerías importadas y listas para usar.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import cloudscraper # Para manejar posibles protecciones de Cloudflare\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "from random import uniform\n",
    "import os\n",
    "\n",
    "print(\"Librerías importadas y listas para usar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19d6b95-8941-45c0-9431-d24d634a4660",
   "metadata": {},
   "source": [
    "Función para Obtener Contenido HTML (fetch_html_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "792dd324-b160-473b-b607-a2cc0dff29e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Función fetch_html_content definida.\n"
     ]
    }
   ],
   "source": [
    "def fetch_html_content(url):\n",
    "    \"\"\"\n",
    "    Obtiene el contenido HTML de una URL usando cloudscraper.\n",
    "\n",
    "    Args:\n",
    "        url (str): La URL de la página a obtener.\n",
    "\n",
    "    Returns:\n",
    "        requests.models.Response: El objeto de respuesta de la solicitud,\n",
    "                                   o None si ocurre un error significativo.\n",
    "    \"\"\"\n",
    "    print(f\"Fetching HTML desde: {url}\")\n",
    "    try:\n",
    "        scraper = cloudscraper.create_scraper(\n",
    "            browser={\n",
    "                'browser': 'chrome',\n",
    "                'platform': 'windows',\n",
    "                'mobile': False\n",
    "            }\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error al crear la instancia de cloudscraper: {e}. Intentando con requests.get().\")\n",
    "        try:\n",
    "            time.sleep(uniform(2, 4)) # Pausa antes de reintentar\n",
    "            response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=30) # Aumentado timeout\n",
    "            response.raise_for_status()\n",
    "            print(f\"Contenido obtenido con requests.get() (Código de estado: {response.status_code})\")\n",
    "            return response\n",
    "        except requests.exceptions.HTTPError as http_err_req:\n",
    "            print(f\"Error HTTP (requests.get) al acceder a {url}: {http_err_req} (Código: {response.status_code if 'response' in locals() and response else 'N/A'})\")\n",
    "            return None\n",
    "        except requests.exceptions.RequestException as req_err_req:\n",
    "            print(f\"Error de red/conexión (requests.get) al acceder a {url}: {req_err_req}\")\n",
    "            return None\n",
    "\n",
    "    time.sleep(uniform(2.5, 5.5)) # Aumentar ligeramente la pausa respetuosa\n",
    "\n",
    "    response = None\n",
    "    try:\n",
    "        response = scraper.get(url, timeout=30) # Aumentado timeout\n",
    "        response.raise_for_status() \n",
    "        print(f\"Contenido obtenido exitosamente con cloudscraper (Código de estado: {response.status_code})\")\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        print(f\"Error HTTP (cloudscraper) al acceder a {url}: {http_err} (Código: {response.status_code if response else 'N/A'})\")\n",
    "        return None\n",
    "    except requests.exceptions.RequestException as req_err:\n",
    "        print(f\"Error de red/conexión (cloudscraper) al acceder a {url}: {req_err}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Ocurrió un error inesperado (cloudscraper) al acceder a {url}: {e}\")\n",
    "        return None\n",
    "        \n",
    "    return response\n",
    "\n",
    "print(\"Función fetch_html_content definida.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a6feca-de76-464d-a923-17f8dfd5d76c",
   "metadata": {},
   "source": [
    "Función para Obtener Datos Generales de Partidos de una LIGA (get_understat_league_general_match_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b64c8f19-6b71-43d3-8787-2849638dbfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Función get_understat_league_general_match_data definida.\n"
     ]
    }
   ],
   "source": [
    "def get_understat_league_general_match_data(league_name_url, year, fetch_function):\n",
    "    \"\"\"\n",
    "    Extrae la lista general de partidos de una LIGA para una temporada específica de Understat.com.\n",
    "    Esta función obtiene la variable 'datesData' de la página de la LIGA.\n",
    "\n",
    "    Args:\n",
    "        league_name_url (str): El nombre de la liga tal como se usa en la URL de Understat (ej. \"La_liga\").\n",
    "        year (int): El año de inicio de la temporada.\n",
    "        fetch_function (function): La función a usar para obtener el contenido HTML.\n",
    "\n",
    "    Returns:\n",
    "        list: Una lista de diccionarios (datos crudos de 'datesData'), o None si falla.\n",
    "    \"\"\"\n",
    "    url = f\"https://understat.com/league/{league_name_url}/{year}\" # URL para la página de la liga\n",
    "    \n",
    "    response = fetch_function(url)\n",
    "\n",
    "    if response is None or response.status_code != 200:\n",
    "        return None\n",
    "\n",
    "    html_content = response.text\n",
    "    soup = BeautifulSoup(html_content, 'lxml')\n",
    "    \n",
    "    script_tags = soup.find_all('script')\n",
    "    match_data_string = None\n",
    "\n",
    "    for script in script_tags:\n",
    "        if script.string and 'datesData' in script.string: # 'datesData' en la página de la liga contiene todos los partidos\n",
    "            match = re.search(r\"datesData\\s*=\\s*JSON\\.parse\\s*\\(\\s*'(.*?)'\\s*\\)\", script.string)\n",
    "            if match:\n",
    "                match_data_string = match.group(1)\n",
    "                break\n",
    "    \n",
    "    if not match_data_string:\n",
    "        print(f\"No se pudo encontrar la cadena de datos 'datesData' en la página de la liga {league_name_url} para el año {year}.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        processed_string = bytes(match_data_string, \"utf-8\").decode(\"unicode_escape\")\n",
    "        data = json.loads(processed_string)\n",
    "    except Exception as e:\n",
    "        print(f\"Error al decodificar o parsear JSON para datesData (liga: {league_name_url}, año: {year}): {e}\")\n",
    "        return None\n",
    "            \n",
    "    if data:\n",
    "        print(f\"Datos generales de partidos extraídos para la liga {league_name_url} {year}. {len(data)} partidos encontrados.\")\n",
    "        return data \n",
    "    else:\n",
    "        print(f\"No se encontraron datos de partidos en el JSON parseado para la liga {league_name_url} {year}.\")\n",
    "        return None\n",
    "\n",
    "print(\"Función get_understat_league_general_match_data definida.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b923f41a-9288-467d-9a58-caee8a7e7007",
   "metadata": {},
   "source": [
    "Función para Obtener Datos Detallados de un Partido Individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3db64404-c252-47c1-9e2a-17e29c8f9cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Función get_understat_single_match_detailed_data definida.\n"
     ]
    }
   ],
   "source": [
    "def get_understat_single_match_detailed_data(match_id, fetch_function):\n",
    "    \"\"\"\n",
    "    Extrae datos detallados (incluyendo 'shots_data' y 'rosters_data')\n",
    "    de una página de partido individual de Understat.com.\n",
    "    \"\"\"\n",
    "    url = f\"https://understat.com/match/{match_id}\"\n",
    "    \n",
    "    response = fetch_function(url)\n",
    "\n",
    "    if response is None or response.status_code != 200:\n",
    "        return None\n",
    "\n",
    "    html_content = response.text\n",
    "    soup = BeautifulSoup(html_content, 'lxml')\n",
    "    \n",
    "    script_tags = soup.find_all('script')\n",
    "    \n",
    "    extracted_data = {\n",
    "        \"shots_data\": None,\n",
    "        \"rosters_data\": None \n",
    "    }\n",
    "\n",
    "    patterns = {\n",
    "        \"shots_data\": r\"shotsData\\s*=\\s*JSON\\.parse\\s*\\(\\s*'(.*?)'\\s*\\)\",\n",
    "        \"rosters_data\": r\"rostersData\\s*=\\s*JSON\\.parse\\s*\\(\\s*'(.*?)'\\s*\\)\"\n",
    "    }\n",
    "\n",
    "    for script in script_tags:\n",
    "        if script.string:\n",
    "            for data_key, pattern in patterns.items():\n",
    "                if extracted_data[data_key] is not None: \n",
    "                    continue\n",
    "                match = re.search(pattern, script.string)\n",
    "                if match:\n",
    "                    data_string = match.group(1)\n",
    "                    try:\n",
    "                        processed_string = bytes(data_string, \"utf-8\").decode(\"unicode_escape\")\n",
    "                        extracted_data[data_key] = json.loads(processed_string)\n",
    "                        print(f\"  Datos para '{data_key}' (partido {match_id}) parseados exitosamente.\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"  Error al decodificar JSON para {data_key} (partido {match_id}): {e}\")\n",
    "                        \n",
    "    if extracted_data.get(\"rosters_data\") is None: \n",
    "        print(f\"  No se pudo extraer 'rosters_data' de la página del partido {match_id}.\")\n",
    "        return None \n",
    "        \n",
    "    return extracted_data\n",
    "\n",
    "print(\"Función get_understat_single_match_detailed_data definida.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59edce43-c57c-4c5f-910d-1e81fcd839d0",
   "metadata": {},
   "source": [
    "Función Principal para Orquestar el Scraping por Liga y Temporadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1c43261-f357-4a6c-95c2-8da7f3305e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Función scrape_league_data_for_model definida.\n"
     ]
    }
   ],
   "source": [
    "def scrape_league_data_for_model(league_url_name, league_print_name, start_year, end_year, fetch_function):\n",
    "    \"\"\"\n",
    "    Orquesta la obtención de datos de partidos de una liga para un rango de temporadas\n",
    "    y los procesa para crear un DataFrame con las columnas deseadas.\n",
    "    \"\"\"\n",
    "    all_matches_for_all_seasons = []\n",
    "\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        print(f\"\\n--- Iniciando scraping para {league_print_name} - Temporada {year}/{year+1} ---\")\n",
    "        \n",
    "        # 1. Obtener la lista general de partidos para la LIGA y la temporada\n",
    "        general_match_list_for_league = get_understat_league_general_match_data(\n",
    "            league_name_url=league_url_name,\n",
    "            year=year,\n",
    "            fetch_function=fetch_function\n",
    "        )\n",
    "\n",
    "        if not general_match_list_for_league:\n",
    "            print(f\"No se pudo obtener la lista general de partidos para {league_print_name} {year}. Omitiendo esta temporada.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nProcesando {len(general_match_list_for_league)} partidos de {league_print_name} {year} para obtener detalles...\")\n",
    "        for i, general_info in enumerate(general_match_list_for_league):\n",
    "            match_id = general_info.get('id')\n",
    "            match_datetime = general_info.get('datetime')\n",
    "\n",
    "            if not match_id or not general_info.get('isResult'):\n",
    "                print(f\"Omitiendo partido general #{i+1} de la liga (ID: {match_id}) por falta de ID o no ser resultado final.\")\n",
    "                continue\n",
    "\n",
    "            home_team_name = general_info.get('h', {}).get('title')\n",
    "            away_team_name = general_info.get('a', {}).get('title')\n",
    "            home_team_goal = int(general_info.get('goals', {}).get('h', 0))\n",
    "            away_team_goal = int(general_info.get('goals', {}).get('a', 0))\n",
    "\n",
    "            if home_team_goal > away_team_goal:\n",
    "                resultado = 'H'\n",
    "            elif away_team_goal > home_team_goal:\n",
    "                resultado = 'A'\n",
    "            else:\n",
    "                resultado = 'D'\n",
    "            \n",
    "            print(f\"\\nObteniendo detalles para partido ID: {match_id} ({i+1}/{len(general_match_list_for_league)}) - {home_team_name} vs {away_team_name}\")\n",
    "            detailed_payload = get_understat_single_match_detailed_data(match_id, fetch_function)\n",
    "\n",
    "            home_aggression_proxy = 0\n",
    "            away_aggression_proxy = 0\n",
    "\n",
    "            if detailed_payload and detailed_payload.get(\"rosters_data\"):\n",
    "                rosters = detailed_payload[\"rosters_data\"]\n",
    "                if 'h' in rosters:\n",
    "                    for player_id, p_stats in rosters['h'].items():\n",
    "                        home_aggression_proxy += int(p_stats.get('yellow_card', 0)) * 1\n",
    "                        home_aggression_proxy += int(p_stats.get('red_card', 0)) * 3\n",
    "                if 'a' in rosters:\n",
    "                    for player_id, p_stats in rosters['a'].items():\n",
    "                        away_aggression_proxy += int(p_stats.get('yellow_card', 0)) * 1\n",
    "                        away_aggression_proxy += int(p_stats.get('red_card', 0)) * 3\n",
    "                # print(f\"  Agresión Proxy -> Local: {home_aggression_proxy}, Visitante: {away_aggression_proxy}\")\n",
    "            else:\n",
    "                print(f\"  No se pudo obtener rosters_data para el partido {match_id}. Agresión no calculada.\")\n",
    "                home_aggression_proxy = None \n",
    "                away_aggression_proxy = None\n",
    "\n",
    "            all_matches_for_all_seasons.append({\n",
    "                \"season_year_start\": year, # Añadimos el año de la temporada\n",
    "                \"league_name\": league_print_name, # Añadimos el nombre de la liga\n",
    "                \"match_date\": pd.to_datetime(match_datetime).date() if match_datetime else None,\n",
    "                \"home_team_name\": home_team_name,\n",
    "                \"away_team_name\": away_team_name,\n",
    "                \"home_team_goal\": home_team_goal,\n",
    "                \"away_team_goal\": away_team_goal,\n",
    "                \"home_aggression\": home_aggression_proxy,\n",
    "                \"away_aggression\": away_aggression_proxy,\n",
    "                \"resultado\": resultado\n",
    "            })\n",
    "        print(f\"--- Finalizado scraping para {league_print_name} - Temporada {year}/{year+1} ---\")\n",
    "\n",
    "\n",
    "    if not all_matches_for_all_seasons:\n",
    "        print(f\"No se procesaron datos de partidos para la liga {league_print_name} en el rango de años especificado.\")\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    final_df = pd.DataFrame(all_matches_for_all_seasons)\n",
    "    return final_df\n",
    "\n",
    "print(\"Función scrape_league_data_for_model definida.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8f676e-2afd-4f97-8434-d0f8a23f4b82",
   "metadata": {},
   "source": [
    "Ejecución del Proceso para La Liga (2016-2024) y Guardado del CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7672065f-219c-4c0a-9472-a78097901ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando Proceso Completo para La Liga - Temporadas 2016-2024 ---\n",
      "\n",
      "--- Iniciando scraping para La Liga - Temporada 2016/2017 ---\n",
      "Fetching HTML desde: https://understat.com/league/La_liga/2016\n",
      "Contenido obtenido exitosamente con cloudscraper (Código de estado: 200)\n",
      "Datos generales de partidos extraídos para la liga La_liga 2016. 380 partidos encontrados.\n",
      "\n",
      "Procesando 380 partidos de La Liga 2016 para obtener detalles...\n",
      "\n",
      "Obteniendo detalles para partido ID: 1779 (1/380) - Malaga vs Osasuna\n",
      "Fetching HTML desde: https://understat.com/match/1779\n",
      "Contenido obtenido exitosamente con cloudscraper (Código de estado: 200)\n",
      "  Datos para 'shots_data' (partido 1779) parseados exitosamente.\n",
      "  Datos para 'rosters_data' (partido 1779) parseados exitosamente.\n",
      "\n",
      "Obteniendo detalles para partido ID: 1780 (2/380) - Deportivo La Coruna vs Eibar\n",
      "Fetching HTML desde: https://understat.com/match/1780\n",
      "Contenido obtenido exitosamente con cloudscraper (Código de estado: 200)\n",
      "  Datos para 'shots_data' (partido 1780) parseados exitosamente.\n",
      "  Datos para 'rosters_data' (partido 1780) parseados exitosamente.\n",
      "\n",
      "Obteniendo detalles para partido ID: 1781 (3/380) - Barcelona vs Real Betis\n",
      "Fetching HTML desde: https://understat.com/match/1781\n",
      "Contenido obtenido exitosamente con cloudscraper (Código de estado: 200)\n",
      "  Datos para 'shots_data' (partido 1781) parseados exitosamente.\n",
      "  Datos para 'rosters_data' (partido 1781) parseados exitosamente.\n",
      "\n",
      "Obteniendo detalles para partido ID: 1782 (4/380) - Granada vs Villarreal\n",
      "Fetching HTML desde: https://understat.com/match/1782\n",
      "Contenido obtenido exitosamente con cloudscraper (Código de estado: 200)\n",
      "  Datos para 'shots_data' (partido 1782) parseados exitosamente.\n",
      "  Datos para 'rosters_data' (partido 1782) parseados exitosamente.\n",
      "\n",
      "Obteniendo detalles para partido ID: 1783 (5/380) - Sevilla vs Espanyol\n",
      "Fetching HTML desde: https://understat.com/match/1783\n",
      "Contenido obtenido exitosamente con cloudscraper (Código de estado: 200)\n",
      "  Datos para 'shots_data' (partido 1783) parseados exitosamente.\n",
      "  Datos para 'rosters_data' (partido 1783) parseados exitosamente.\n",
      "\n",
      "Obteniendo detalles para partido ID: 1784 (6/380) - Sporting Gijon vs Athletic Club\n",
      "Fetching HTML desde: https://understat.com/match/1784\n",
      "Contenido obtenido exitosamente con cloudscraper (Código de estado: 200)\n",
      "  Datos para 'shots_data' (partido 1784) parseados exitosamente.\n",
      "  Datos para 'rosters_data' (partido 1784) parseados exitosamente.\n",
      "\n",
      "Obteniendo detalles para partido ID: 1785 (7/380) - Real Sociedad vs Real Madrid\n",
      "Fetching HTML desde: https://understat.com/match/1785\n",
      "Contenido obtenido exitosamente con cloudscraper (Código de estado: 200)\n",
      "  Datos para 'shots_data' (partido 1785) parseados exitosamente.\n",
      "  Datos para 'rosters_data' (partido 1785) parseados exitosamente.\n",
      "\n",
      "Obteniendo detalles para partido ID: 1786 (8/380) - Atletico Madrid vs Alaves\n",
      "Fetching HTML desde: https://understat.com/match/1786\n"
     ]
    }
   ],
   "source": [
    "# --- Configuración del Scraping para La Liga ---\n",
    "target_league_url_name_param = \"La_liga\" # Nombre de La Liga para la URL de Understat\n",
    "target_league_print_name_param = \"La Liga\" # Nombre para mostrar y para la columna en el DataFrame\n",
    "# Rango de años de inicio de temporada\n",
    "# 2016 para 2016/17, ..., 2023 para 2023/24.\n",
    "# Si quieres la temporada 2024/25 (que inicia en 2024), incluye 2024.\n",
    "# El año actual es 2025, la temporada 2024/25 ya debería estar avanzada o completa.\n",
    "start_season_year_param = 2016\n",
    "end_season_year_param = 2024 # Incluye la temporada que comienza en 2024 (2024/2025)\n",
    "\n",
    "print(f\"--- Iniciando Proceso Completo para {target_league_print_name_param} - Temporadas {start_season_year_param}-{end_season_year_param} ---\")\n",
    "\n",
    "# Llamar a la función principal que orquesta todo\n",
    "df_la_liga_model = scrape_league_data_for_model(\n",
    "    league_url_name=target_league_url_name_param,\n",
    "    league_print_name=target_league_print_name_param,\n",
    "    start_year=start_season_year_param,\n",
    "    end_year=end_season_year_param,\n",
    "    fetch_function=fetch_html_content\n",
    ")\n",
    "\n",
    "# Mostrar información del DataFrame resultante y guardarlo\n",
    "if not df_la_liga_model.empty:\n",
    "    print(\"\\n\\n--- DataFrame Final Generado para La Liga ---\")\n",
    "    print(f\"Total de partidos procesados (filas): {df_la_liga_model.shape[0]}\")\n",
    "    print(f\"Columnas generadas: {df_la_liga_model.shape[1]}\")\n",
    "    \n",
    "    print(\"\\nPrimeras 5 filas del DataFrame:\")\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    print(df_la_liga_model.head())\n",
    "    \n",
    "    print(\"\\nÚltimas 5 filas del DataFrame (para ver los años más recientes):\")\n",
    "    print(df_la_liga_model.tail())\n",
    "    \n",
    "    print(\"\\nInformación del DataFrame:\")\n",
    "    df_la_liga_model.info()\n",
    "    \n",
    "    # Guardar en CSV\n",
    "    # !!! IMPORTANTE: VERIFICA Y CAMBIA ESTA RUTA SI ES NECESARIO !!!\n",
    "    output_csv_path_la_liga = r\"C:\\Users\\juand\\Downloads\\Proyecto_analisis\\understat_la_liga_2016-2024_model_data.csv\"\n",
    "    try:\n",
    "        output_csv_directory = os.path.dirname(output_csv_path_la_liga)\n",
    "        if output_csv_directory and not os.path.exists(output_csv_directory): # Solo crear si el directorio no es la raíz y no existe\n",
    "            os.makedirs(output_csv_directory)\n",
    "            print(f\"\\nDirectorio para CSV creado: {output_csv_directory}\")\n",
    "\n",
    "        df_la_liga_model.to_csv(output_csv_path_la_liga, index=False, encoding='utf-8-sig')\n",
    "        print(f\"\\nDataFrame de La Liga guardado exitosamente en: {output_csv_path_la_liga}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError al guardar el CSV de La Liga: {e}\")\n",
    "            \n",
    "else:\n",
    "    print(\"\\nEl DataFrame final para La Liga está vacío. No se procesaron datos o hubo errores.\")\n",
    "\n",
    "print(f\"\\n--- Proceso de Scraping para {target_league_print_name_param} Finalizado ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
